!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.ecog.ECoG {
            filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug_noise.h5',
            which_set: 'augment',
            center: True,
            fold: %(fold)i,
    },
    model: !obj:pylearn2.models.mlp.MLP {
            input_space: !obj:pylearn2.space.VectorSpace {
                    dim: 21930,
                    },
            layers: [ 
                    !obj:pylearn2.models.mlp.Tanh {
                    layer_name: 'h0',
                    #num_units: 150,
                    #num_pieces: 2,
                    dim: %(L0)i,
                    istdev: .005,
                    }, 
                       !obj:pylearn2.models.mlp.Softmax {
                             layer_name: 'y',
                             n_classes: 57,
                             istdev: .005,
                             }
                        ],
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 20,
        learning_rate: .001,
        train_iteration_mode: 'sequential',
        monitoring_dataset:
            {
                'train' : !obj:pylearn2.datasets.ecog.ECoG {
                                filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug_noise.h5',
                                which_set: 'train',
                                center: True,
                                fold: %(fold)i,
                          },
                'valid' : !obj:pylearn2.datasets.ecog.ECoG {
                                filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug_noise.h5',
                                which_set: 'valid',
                                center: True,
                                fold: %(fold)i,
                          },
                'test' : !obj:pylearn2.datasets.ecog.ECoG {
                                filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug_noise.h5',
                                which_set: 'test',
                                center: True,
                                fold: %(fold)i,
                          },
            },
        monitoring_batch_size: 50,
        monitor_iteration_mode: 'sequential',
        monitoring_costs: {'no_dropout': !obj:pylearn2.costs.mlp.Default {}, },
        cost: !obj:pylearn2.costs.cost.SumOfCosts { costs: [
                #[1., !obj:pylearn2.costs.mlp.Default {} ],
                 [1., !obj:pylearn2.costs.mlp.dropout.Dropout {
                         input_include_probs: { 'h0': .8 },
                         input_scales: { 'h0': 1.25}
                         } ],
                [1., !obj:pylearn2.costs.mlp.WeightDecay {
                       coeffs: { 'h0': .0001, 'h1': .0001, 'y': .0001 },
                       },
                ],
            ]
        },
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: .5,
            nesterov_momentum: True
        },
        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
            decay_factor: 1.00004,
            min_lr: .000001
        },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_y_misclass",
                    prop_decrease: 0.,
                    N: 10
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: 100
                }
            ]
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_y_misclass',
             save_path: %(filename)s,
        },
    !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
        start: 1,
        saturate: 20,
        final_momentum: .9
        }
    ]
}
