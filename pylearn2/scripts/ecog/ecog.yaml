!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.ecog.ECoG {
            filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug.h5',
            which_set: 'train',
            center: True,
            fold: %(fold)i,
            level_classes: True,
    },
    model: !obj:pylearn2.models.mlp.MLP {
            input_space: !obj:pylearn2.space.VectorSpace {
                    dim: 21930,
                    },
            layers: [ 
                    !obj:pylearn2.models.mlp.Tanh {
                    layer_name: 'h0',
                    dim: 706,
                    istdev: .00021363144,
                    max_col_norm: 0.4618327012067067
                    }, 
                       !obj:pylearn2.models.mlp.Softmax {
                             layer_name: 'y',
                             n_classes: 57,
                             istdev: .00021363144,
                             }
                        ],
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 93,
        learning_rate: .02182468684,
        train_iteration_mode: 'sequential',
        monitoring_dataset:
            {
                'train' : *train,
                'valid' : !obj:pylearn2.datasets.ecog.ECoG {
                                filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug.h5',
                                which_set: 'valid',
                                center: True,
                                fold: %(fold)i,
                                level_classes: True,
                          },
                'test' : !obj:pylearn2.datasets.ecog.ECoG {
                                filename: '${PYLEARN2_DATA_PATH}/ecog/EC2_CV_85_nobaseline_aug.h5',
                                which_set: 'test',
                                center: True,
                                fold: %(fold)i,
                                level_classes: True,
                          },
            },
        monitoring_batch_size: 50,
        monitor_iteration_mode: 'sequential',
        monitoring_costs: {'no_dropout': !obj:pylearn2.costs.mlp.Default {}, },
        cost: !obj:pylearn2.costs.cost.SumOfCosts { costs: [
                #[1., !obj:pylearn2.costs.mlp.Default {} ],
                 [1., !obj:pylearn2.costs.mlp.dropout.Dropout {
                         default_input_include_prob: 0.6991945459587083,
                         default_input_scale: 1.9846199238472535,
                         input_include_probs: { 'h0': 0.7275318100349784 },
                         input_scales: { 'h0': 2.000959254762546}
                         } ],
                [1., !obj:pylearn2.costs.mlp.WeightDecay {
                       coeffs: { 'h0': .00000354673, 'y': .00000354673 },
                       },
                ],
            ]
        },
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: .5,
            nesterov_momentum: True
        },
        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
            decay_factor: 1.00004,
            min_lr: .000001
        },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_y_misclass",
                    prop_decrease: 0.,
                    N: 10
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: 100
                }
            ]
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_y_misclass',
             save_path: %(filename)s,
        },
    !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
        start: 1,
        saturate: 16,
        final_momentum: 0.7859342918993639
        }
    ]
}
